from pathlib import Path
from app.include.logging_config import logger as log
from qdrant_client import QdrantClient, models
from qdrant_client.models import Distance, VectorParams
from tqdm import tqdm
from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter
from app.include.config import config
from app.include.embeddings.qwen_embedding import QwenEmbedding
import uuid


COLLECTION_NAME = "sleepteryGPT"

embeddings_qwen = QwenEmbedding(
    model=config.EMBEDDING_MODEL_ID,
    dimensions=config.VECTOR_DIMENSION
)

qdrant_client = QdrantClient(host="localhost", port=6445)

# 1. –ì–†–£–ë–ê–Ø –†–ê–ó–ë–ò–í–ö–ê (–ü–æ –≥–ª–∞–≤–∞–º)
markdown_splitter = MarkdownHeaderTextSplitter(
    headers_to_split_on=[
        ('#', 'chapter'), 
        ('##', 'subtitle'),
    ],
    strip_headers=False 
)

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=400,       
    chunk_overlap=50,
    length_function=len,
    separators=["\n", ". ", "! ",]
)

class SleepAiRagEmbeddingConfig:
    @staticmethod
    def run_pipeline(file_paths: list[Path]):
        # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã —Ç–µ—Å—Ç–∞
        if qdrant_client.collection_exists(collection_name=f"{COLLECTION_NAME}_test"):
            qdrant_client.delete_collection(collection_name=f"{COLLECTION_NAME}_test")
            
        log.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {f'{COLLECTION_NAME}_test'}")
        qdrant_client.recreate_collection(
            collection_name=f"{COLLECTION_NAME}_test",
            vectors_config=VectorParams(size=config.VECTOR_DIMENSION, distance=Distance.COSINE)
        )

        for file in file_paths:
            log.info(f"\nüìò –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {file.name}")
            with open(file, "r", encoding="utf-8") as f:
                content = f.read()
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –∫—Ä–∞—Å–∏–≤–æ
            docs_processed = SleepAiRagEmbeddingConfig.process_markdown(content, file.name)
            
            # –ì–æ—Ç–æ–≤–∏–º —Ç–µ–∫—Å—Ç—ã –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            batch_texts = [d['page_content_for_embedding'] for d in docs_processed]
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∞
            try:
                vectors = SleepAiRagEmbeddingConfig.get_batch_embeddings(batch_texts)
            except Exception as e:
                log.error(f"Critical Error during embedding: {e}")
                return

            points = []
            for i, doc in enumerate(docs_processed):
                # –ï—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤–µ—Ä–Ω—É–ª–æ—Å—å –º–µ–Ω—å—à–µ —á–µ–º —Ç–µ–∫—Å—Ç–æ–≤ (—Å–±–æ–π), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if i >= len(vectors): 
                    break
                    
                points.append(
                    models.PointStruct(
                        id=str(uuid.uuid4()), # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
                        vector=vectors[i],
                        payload={
                            "source_file": file.name,
                            "chapter": doc['metadata'].get('chapter', '–û–±—â–µ–µ'),
                            "subtitle": doc['metadata'].get('subtitle', ''),
                            "text": doc['text_content'], # –ß–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∫–∞–∑–∞ —é–∑–µ—Ä—É
                            "full_context": doc['page_content_for_embedding']
                        }
                    )
                )
            
            log.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ {len(points)} —Ç–æ—á–µ–∫ –≤ Qdrant...")
            for batch_start in tqdm(range(0, len(points), config.BATCH_SIZE)):
                batch_points = points[batch_start:batch_start + config.BATCH_SIZE]
                qdrant_client.upsert(
                    collection_name=f"{COLLECTION_NAME}_test",
                    points=batch_points
                )

        log.info("\n‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

    @staticmethod
    def process_markdown(content: str, filename: str) -> list:
        final_chunks = []
        md_docs = markdown_splitter.split_text(content)
        split_docs = text_splitter.split_documents(md_docs)
        
        for doc in split_docs:
            meta = doc.metadata
            text = doc.page_content.strip()
            
            if len(text) < 20: # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º—É—Å–æ—Ä –∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –±–µ–∑ —Ç–µ–∫—Å—Ç–∞
                continue

            chapter = meta.get('chapter', '')
            subtitle = meta.get('subtitle', '')
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ò–ò (—á—Ç–æ–±—ã –æ–Ω –ø–æ–Ω–∏–º–∞–ª –æ —á–µ–º —Ä–µ—á—å)
            # –ù–æ —Å–∞–º text —Å–æ—Ö—Ä–∞–Ω—è–µ–º —á–∏—Å—Ç—ã–º
            content_for_embedding = f"–¢–µ–º–∞: {chapter} -> {subtitle}\n–¢–µ–∫—Å—Ç: {text}"
            
            final_chunks.append({
                "text_content": text,
                "page_content_for_embedding": content_for_embedding,
                "metadata": meta
            })
            
        log.info(f"–†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(final_chunks)} –∞–∫–∫—É—Ä–∞—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.")
        # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ –ø–æ–∫–∞–∂–µ–º –ø—Ä–∏–º–µ—Ä –ø–µ—Ä–≤—ã—Ö 2 —á–∞–Ω–∫–æ–≤
        if final_chunks:
            log.info(f"–ü—Ä–∏–º–µ—Ä —á–∞–Ω–∫–∞ #1:\n---\n{final_chunks[0]['text_content']}\n---")
            
        return final_chunks

    @staticmethod
    def get_batch_embeddings(texts: list) -> list:
        all_embeddings = []
        # –ë–∞—Ç—á –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å, –µ—Å–ª–∏ API –ø–∞–¥–∞–µ—Ç
        safe_batch_size = 5 
        for i in tqdm(range(0, len(texts), safe_batch_size), desc="–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"):
            batch = texts[i:i + safe_batch_size]
            embeddings = embeddings_qwen.embed_documents(batch)
            all_embeddings.extend(embeddings)
        return all_embeddings

if __name__ == "__main__":
    SleepAiRagEmbeddingConfig.run_pipeline(
        file_paths=[Path("app/dialog_ai/resources/RAG/knowledge_base/book_test.md")] 
    )